{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "provincial-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arviz as az\n",
    "import math\n",
    "# import pymc3 as pm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from google.protobuf import text_format\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import griddata\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import statistics as stat\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handy-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_t_rvs(m, S, df=np.inf, n=1):\n",
    "    '''generate random variables of multivariate t distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : array_like\n",
    "        mean of random variable, length determines dimension of random variable\n",
    "    S : array_like\n",
    "        square array of covariance  matrix\n",
    "    df : int or float\n",
    "        degrees of freedom\n",
    "    n : int\n",
    "        number of observations, return random array will be (n, len(m))\n",
    "    Returns\n",
    "    -------\n",
    "    rvs : ndarray, (n, len(m))\n",
    "        each row is an independent draw of a multivariate t distributed\n",
    "        random variable\n",
    "    '''\n",
    "    m = np.asarray(m)\n",
    "    d = len(m)\n",
    "    if df == np.inf:\n",
    "        x = 1.\n",
    "    else:\n",
    "        x = np.random.chisquare(df, n)/df\n",
    "    z = np.random.multivariate_normal(np.zeros(d),S,(n,))\n",
    "    return m + z/np.sqrt(x)[:,None]   # same output format as random.multivariate_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-warning",
   "metadata": {},
   "source": [
    "# Generate data\n",
    "\n",
    "assuming delta = I identical for all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smooth-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_etas(mus, deltas_cov, cluster_alloc):\n",
    "    np.random.seed(seed=233423)\n",
    "    out = np.vstack([[mvn.rvs(mean = mus[i,:], cov = deltas_cov) for i in cluster_alloc]])\n",
    "    return out\n",
    "\n",
    "def generate_data(Lambda, etas, sigma_bar_cov):\n",
    "    np.random.seed(seed=233423)\n",
    "    means = np.matmul(Lambda,etas.T)\n",
    "    sigma_bar_cov_mat = np.diag(sigma_bar_cov)\n",
    "    out = np.vstack([multivariate_t_rvs(m = means[:,i], S = sigma_bar_cov_mat, df = 3)[0] for i in range(etas.shape[0])])\n",
    "    return out\n",
    "\n",
    "def create_lambda(p,d):\n",
    "    #if p % d != 0:\n",
    "      #  raise ValueError(\"Non compatible dimensions p and d: p={0}, d={1}\".format(p,d))\n",
    "    \n",
    "    h = math.ceil(p/d)\n",
    "    Lambda=np.zeros((p,d))\n",
    "    for i in range(d-1):\n",
    "        Lambda[i*h:i*h+h,i] = np.ones(h)\n",
    "    \n",
    "    Lambda[(d-1)*h:,d-1] = np.ones(p-(d-1)*h)\n",
    "    return Lambda\n",
    "\n",
    "def create_mus(d,M,dist):\n",
    "    mus = np.zeros((M,d))\n",
    "    tot_range = (M-1)*dist \n",
    "    max_mu = tot_range/2\n",
    "    for i in range(M):\n",
    "        mus[i,:] = np.repeat(max_mu-i*dist, d)\n",
    "        \n",
    "    return mus\n",
    "\n",
    "def create_cluster_alloc(n_pc,M):\n",
    "    return np.repeat(range(M),n_pc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fiscal-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "dist=5\n",
    "p_s = [100, 200, 400]\n",
    "d_s = [2, 5, 10]\n",
    "M_s = [4, 8, 12]\n",
    "n_percluster_s = [50]\n",
    "\n",
    "for p in p_s:\n",
    "    sigma_bar_prec = np.repeat(2, p)\n",
    "    sigma_bar_cov = 1/sigma_bar_prec\n",
    "    for d in d_s:\n",
    "        lamb = create_lambda(p,d)\n",
    "        delta_cov = np.eye(d)\n",
    "        for M in M_s:\n",
    "            mus = create_mus(d,M,dist)\n",
    "            for n_percluster in n_percluster_s:                \n",
    "                cluster_alloc = create_cluster_alloc(n_percluster,M)\n",
    "                etas = generate_etas(mus, delta_cov, cluster_alloc)\n",
    "                data = generate_data(lamb, etas, sigma_bar_cov)\n",
    "                #with open(\"datasets/stud_p_{0}_d_{1}_M_{2}_npc_{3}_data.csv\".format(p,d,M,n_percluster),\"w+\") as my_csv:\n",
    "                    csvWriter = csv.writer(my_csv, delimiter=',')\n",
    "                    csvWriter.writerows(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charitable-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "p_s = [100, 200, 400]\n",
    "d_s = [2, 5, 10]\n",
    "M_s = [4, 8, 12]\n",
    "n_percluster_s = [50]\n",
    "\n",
    "for p,dtrue,M,npc in product(p_s, d_s, M_s, n_percluster_s):\n",
    "    with open(\"datasets/stud_p_{0}_d_{1}_M_{2}_npc_{3}_data.csv\".format(p,dtrue,M,npc), newline='') as my_csv:\n",
    "        data = pd.read_csv(my_csv, sep=',', header=None).values\n",
    "        \n",
    "    # scaling of data\n",
    "    centering_var=stat.median(np.mean(data,0))\n",
    "    scaling_var=stat.median(np.std(data,0))\n",
    "    data_scaled=(data-centering_var)/scaling_var\n",
    "\n",
    "    # SVD decomposition to estimate the number of latent factors d (following Chandra)\n",
    "    svd = TruncatedSVD(n_components=10, n_iter=7, random_state=42)\n",
    "    svd.fit(data_scaled)\n",
    "\n",
    "    # d is set to be the minimum number of eigenbalues explaining at least 90% of the variability in the data.\n",
    "    cum_eigs= np.cumsum(svd.singular_values_)/svd.singular_values_.sum()\n",
    "    d=np.min(np.where(cum_eigs>.90))\n",
    "    \n",
    "    #with open(\"latent_dim/stud_p_{0}_d_{1}_M_{2}_npc_{3}_lat_dim.txt\".format(p,dtrue,M,npc),\"w\") as my_file:\n",
    "                    my_file.write(str(d))\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
