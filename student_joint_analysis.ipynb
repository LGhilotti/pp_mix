{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r6-w9sfUQlXY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KIoW8Ky1Q_BG"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Student_data/lamb_out/lamb_p_100_d_2_M_4_npc_50_out/conc_0.25_out0/alloc_matrix.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b0da670aa995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconc_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconc_dir_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/alloc_matrix.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmy_csv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0malloc_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Student_data/lamb_out/lamb_p_100_d_2_M_4_npc_50_out/conc_0.25_out0/alloc_matrix.csv'"
     ]
    }
   ],
   "source": [
    "p_s = [100]\n",
    "d_s = [2,5]\n",
    "M_s = [4,8]\n",
    "n_percluster_s = [50]\n",
    "conc_dir_s = [0.25, 0.5, 1]\n",
    "rho_s = [5, 10, 20]\n",
    "\n",
    "# Outer cycle for reading the different datasets and perform the estimation\n",
    "for p,dtrue,M,npc in product(p_s, d_s, M_s, n_percluster_s):\n",
    "   # Read the latent dimension for the current datasets (already computed since used also in Chandra)\n",
    "    with open(\"data/Student_data/latent_dim/stud_p_{0}_d_{1}_M_{2}_npc_{3}_lat_dim.txt\".format(p,dtrue,M,npc)) as my_file:\n",
    "        d = int(my_file.read())\n",
    "\n",
    "    list_compare = list()\n",
    "\n",
    "    for conc_dir in conc_dir_s:\n",
    "\n",
    "        with open(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/alloc_matrix.csv\".format(p,dtrue,M,npc,conc_dir), newline='') as my_csv:\n",
    "            alloc_matrix = pd.read_csv(my_csv, sep=',', header=None).values\n",
    "\n",
    "        list_performance = list()\n",
    "        nclus_lamb = np.array([len(np.unique(alloc_matrix[i,:])) for i in range(alloc_matrix.shape[0])])\n",
    "        post_mode_nclus_lamb = stats.mode(nclus_lamb)[0][0] # store in dataframe\n",
    "        post_avg_nclus_lamb = nclus_lamb.mean() # store in dataframe\n",
    "\n",
    "        best_clus_lamb = cluster_estimate(alloc_matrix)\n",
    "        true_clus = np.repeat(range(M),npc)\n",
    "        ari_best_clus_lamb = adjusted_rand_score(true_clus, best_clus_lamb) # store in dataframe\n",
    "\n",
    "        aris_chain_lamb = np.array([adjusted_rand_score(true_clus, alloc_matrix[i,:]) for i in range(alloc_matrix.shape[0])])\n",
    "        mean_aris_lamb, sigma_aris_lamb = np.mean(aris_chain_lamb), np.std(aris_chain_lamb) # store mean_aris in dataframe\n",
    "        CI_aris_lamb = stats.norm.interval(0.95, loc=mean_aris_lamb, scale=sigma_aris_lamb/sqrt(len(aris_chain_lamb))) # store in dataframe\n",
    "        list_performance.append([p,dtrue,d,M,npc,conc_dir,post_mode_nclus_lamb,\n",
    "                                    post_avg_nclus_lamb,ari_best_clus_lamb,mean_aris_lamb,CI_aris_lamb])\n",
    "\n",
    "        list_compare.append([\"lamb\",conc_dir, post_mode_nclus_lamb, post_avg_nclus_lamb,ari_best_clus_lamb,mean_aris_lamb,CI_aris_lamb])\n",
    "\n",
    "        # Save in proper folders similar quantities than for applam\n",
    "        df_performance_lamb = pd.DataFrame(list_performance, columns=('p','dtrue','d','M','npc','dir_concentr','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
    "        df_performance.to_csv(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/df_performance_lamb.csv\".format(p,dtrue,M,npc,conc_dir))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(nclus_lamb)\n",
    "        plt.title(\"number of clusters chain: lamb\")\n",
    "        plt.savefig(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/nclus_chain_lamb.pdf\".format(p,dtrue,M,npc,conc_dir))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "  #for rho in rho_s:\n",
    "    \n",
    "     #with open(\"data/Student_data/applam/app_p_{0}_d_{1}_M_{2}_npc_{3}_out/rho_{0}_out\".format(p,dtrue,M,npc,rho), newline='') as my_csv:\n",
    "       #df_perf_applam = pd.read_csv(my_csv, sep=',')\n",
    "\n",
    "     #list_compare.append([\"applam\", df_perf_applam[[\"intensity\",'mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris']])\n",
    "\n",
    "\n",
    "    df_compare = pd.DataFrame(list_compare, columns=('Model','dir_concentr/intens','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXfO2CTVQ_KH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "joint_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
