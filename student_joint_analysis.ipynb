{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r6-w9sfUQlXY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from pp_mix.interface import cluster_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KIoW8Ky1Q_BG"
   },
   "outputs": [],
   "source": [
    "p_s = [100]\n",
    "d_s = [2,5,8]\n",
    "M_s = [4]\n",
    "n_percluster_s = [50]\n",
    "conc_dir_s = [0.1, 0.5, 1]\n",
    "#rho_s = [5, 10, 20]\n",
    "\n",
    "# Outer cycle for reading the different datasets and perform the estimation\n",
    "for p,dtrue,M,npc in product(p_s, d_s, M_s, n_percluster_s):\n",
    "   # Read the latent dimension for the current datasets (already computed since used also in Chandra)\n",
    "    #with open(\"data/Student_data/latent_dim/stud_p_{0}_d_{1}_M_{2}_npc_{3}_lat_dim.txt\".format(p,dtrue,M,npc)) as my_file:\n",
    "        #d = int(my_file.read())\n",
    "    \n",
    "    d=dtrue\n",
    "    #list_compare = list()\n",
    "\n",
    "    for conc_dir in conc_dir_s:\n",
    "\n",
    "        with open(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out1/alloc_matrix.csv\".format(p,dtrue,M,npc,conc_dir), newline='') as my_csv:\n",
    "            alloc_matrix = pd.read_csv(my_csv, sep=',', header=None).values\n",
    "\n",
    "        list_performance = list()\n",
    "        nclus_lamb = np.array([len(np.unique(alloc_matrix[i,:])) for i in range(alloc_matrix.shape[0])])\n",
    "        post_mode_nclus_lamb = stats.mode(nclus_lamb)[0][0] # store in dataframe\n",
    "        post_avg_nclus_lamb = nclus_lamb.mean() # store in dataframe\n",
    "\n",
    "        best_clus_lamb = cluster_estimate(alloc_matrix)\n",
    "        true_clus = np.repeat(range(M),npc)\n",
    "        ari_best_clus_lamb = adjusted_rand_score(true_clus, best_clus_lamb) # store in dataframe\n",
    "\n",
    "        aris_chain_lamb = np.array([adjusted_rand_score(true_clus, alloc_matrix[i,:]) for i in range(alloc_matrix.shape[0])])\n",
    "        mean_aris_lamb, sigma_aris_lamb = np.mean(aris_chain_lamb), np.std(aris_chain_lamb) # store mean_aris in dataframe\n",
    "        CI_aris_lamb = stats.norm.interval(0.95, loc=mean_aris_lamb, scale=sigma_aris_lamb/sqrt(len(aris_chain_lamb))) # store in dataframe\n",
    "        list_performance.append([p,d,M,npc,conc_dir,post_mode_nclus_lamb,\n",
    "                                    post_avg_nclus_lamb,ari_best_clus_lamb,CI_aris_lamb])\n",
    "\n",
    "        #list_compare.append([\"lamb\",conc_dir, post_mode_nclus_lamb, post_avg_nclus_lamb,ari_best_clus_lamb,CI_aris_lamb])\n",
    "\n",
    "        # Save in proper folders similar quantities than for applam\n",
    "        df_performance_lamb = pd.DataFrame(list_performance, columns=('p','d','M','npc','dir_concentr','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
    "        df_performance_lamb.to_csv(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out1/df_performance_lamb.csv\".format(p,dtrue,M,npc,conc_dir))\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(nclus_lamb)\n",
    "        plt.title(\"number of clusters chain: lamb\")\n",
    "        plt.savefig(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out1/nclus_chain_lamb.pdf\".format(p,dtrue,M,npc,conc_dir))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "  #for rho in rho_s:\n",
    "    \n",
    "     #with open(\"data/Student_data/applam/app_p_{0}_d_{1}_M_{2}_npc_{3}_out/rho_{0}_out\".format(p,dtrue,M,npc,rho), newline='') as my_csv:\n",
    "       #df_perf_applam = pd.read_csv(my_csv, sep=',')\n",
    "\n",
    "     #list_compare.append([\"applam\", df_perf_applam[[\"intensity\",'mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris']])\n",
    "\n",
    "\n",
    "    #df_compare = pd.DataFrame(list_compare, columns=('Model','dir_concentr/intens','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXfO2CTVQ_KH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "joint_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
