{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "joint_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6-w9sfUQlXY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_s = [100, 200, 400]\n",
        "d_s = [2,5,10]\n",
        "M_s = [4,8,12]\n",
        "n_percluster_s = [50]\n",
        "conc_dir_s = [0.25, 0.5, 1]\n",
        "rho_s = [5, 10, 20]\n",
        "\n",
        "# Outer cycle for reading the different datasets and perform the estimation\n",
        "for p,dtrue,M,npc in product(p_s, d_s, M_s, n_percluster_s):\n",
        "   # Read the latent dimension for the current datasets (already computed since used also in Chandra)\n",
        "   with open(\"data/Student_data/latent_dim/stud_p_{0}_d_{1}_M_{2}_npc_{3}_lat_dim.txt\".format(p,dtrue,M,npc)) as my_file:\n",
        "     d = int(my_file.read())\n",
        "\n",
        "  list_compare = list()\n",
        "\n",
        "  for conc_dir in conc_dir_s:\n",
        "\n",
        "    with open(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/alloc_matrix.csv\".format(p,dtrue,M,npc,conc_dir), newline='') as my_csv:\n",
        "      alloc_matrix = pd.read_csv(my_csv, sep=',', header=None).values\n",
        "\n",
        "    list_performance = list()\n",
        "    nclus_lamb = np.array([len(np.unique(alloc_matrix[i,:])) for i in range(alloc_matrix.shape[0])])\n",
        "    post_mode_nclus_lamb = stats.mode(nclus_lamb)[0][0] # store in dataframe\n",
        "    post_avg_nclus_lamb = nclus_lamb.mean() # store in dataframe\n",
        "\n",
        "    best_clus_lamb = cluster_estimate(alloc_matrix)\n",
        "    true_clus = np.repeat(range(M),npc)\n",
        "    ari_best_clus_lamb = adjusted_rand_score(true_clus, best_clus_lamb) # store in dataframe\n",
        "\n",
        "    aris_chain_lamb = np.array([adjusted_rand_score(true_clus, alloc_matrix[i,:]) for i in range(alloc_matrix.shape[0])])\n",
        "    mean_aris_lamb, sigma_aris_lamb = np.mean(aris_chain_lamb), np.std(aris_chain_lamb) # store mean_aris in dataframe\n",
        "    CI_aris_lamb = stats.norm.interval(0.95, loc=mean_aris_lamb, scale=sigma_aris_lamb/sqrt(len(aris_chain_lamb))) # store in dataframe\n",
        "    list_performance.append([p,dtrue,d,M,npc,conc_dir,post_mode_nclus_lamb,\n",
        "                                post_avg_nclus_lamb,ari_best_clus_lamb,mean_aris_lamb,CI_aris_lamb])\n",
        "    \n",
        "    list_compare.append([\"lamb\",conc_dir, post_mode_nclus_lamb, post_avg_nclus_lamb,ari_best_clus_lamb,mean_aris_lamb,CI_aris_lamb])\n",
        "\n",
        "    # Save in proper folders similar quantities than for applam\n",
        "    df_performance_lamb = pd.DataFrame(list_performance, columns=('p','dtrue','d','M','npc','dir_concentr','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
        "    df_performance.to_csv(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/df_performance_lamb.csv\".format(p,dtrue,M,npc,conc_dir))\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    plt.plot(nclus_lamb)\n",
        "    plt.title(\"number of clusters chain: lamb\")\n",
        "    plt.savefig(\"data/Student_data/lamb_out/lamb_p_{0}_d_{1}_M_{2}_npc_{3}_out/conc_{4}_out0/nclus_chain_lamb.pdf\".format(p,dtrue,M,npc,conc_dir))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "  for rho in rho_s:\n",
        "    \n",
        "     with open(\"data/Student_data/applam/app_p_{0}_d_{1}_M_{2}_npc_{3}_out/rho_{0}_out\".format(p,dtrue,M,npc,rho), newline='') as my_csv:\n",
        "       df_perf_applam = pd.read_csv(my_csv, sep=',')\n",
        "\n",
        "     list_compare.append([\"applam\", df_perf_applam[[\"intensity\",'mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris']])\n",
        "\n",
        "\n",
        "  df_compare = pd.DataFrame(list_compare, columns=('Model','dir_concentr/intens','mode_nclus', 'avg_nclus', 'ari_best_clus', 'CI_aris'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KIoW8Ky1Q_BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pXfO2CTVQ_KH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}